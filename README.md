# ğŸŒŸ Machine Learning In-depth Notes

Welcome to **Machine Learning In-depth Notes** ğŸ“˜âœ¨ â€” an **open-source collection** of **from-scratch implementations** of Machine Learning algorithms.  
This project covers **Supervised** ğŸ¤– and **Unsupervised** ğŸ” learning methods, each paired with its **research paper PDF** ğŸ“„.  
Our mission is to **learn by building**, understanding ML from the ground up, and making it accessible to everyone!  

Weâ€™re not stopping here ğŸš¦ â€” coming soon: **NLP ğŸ“, Deep Learning ğŸ§ , and Transformers âš¡**.

---

## ğŸ“‘ Table of Contents
- [ğŸ” Overview](#-overview)
- [âš™ï¸ Implemented Algorithms](#ï¸-implemented-algorithms)
- [ğŸ“‚ Directory Structure](#-directory-structure)
- [ğŸ“– Research Papers](#-research-papers)
- [ğŸ’» How to Use](#-how-to-use)
- [ğŸ¤ Contribute](#-contribute)
- [ğŸš€ Future Roadmap](#-future-roadmap)
- [ğŸ“œ License](#-license)

---

## ğŸ” Overview
This repo is a **hands-on learning resource**. Each algorithm is:
- âœ… Implemented from scratch (no shortcuts!)  
- ğŸ“„ Documented with the original **research paper**  
- ğŸ““ Accompanied by Python scripts & Jupyter Notebooks for demos  

Our goal is to create a **living library** of ML knowledge â€” **practical + theoretical**.

---

## âš™ï¸ Implemented Algorithms

### ğŸ¯ Supervised Learning
- ğŸ“ˆ **Linear Regression**  
- ğŸ“‰ **Logistic Regression**  
- âš¡ **Support Vector Machine (SVM)**  
- ğŸŒ³ **Decision Tree**  
- ğŸŒ² **Random Forest**  
- ğŸ”œ *(more coming soon!)*  

### ğŸ” Unsupervised Learning
- ğŸ”‘ **K-Means Clustering**  
- ğŸ— **Hierarchical Clustering**  
- ğŸ“Š **Principal Component Analysis (PCA)**  
- ğŸ”œ *(more coming soon!)*  

---

## ğŸ“‚ Directory Structure
```text
Machine_Learning_Indepth_Notes/
â”œâ”€â”€ supervised/
â”‚   â”œâ”€â”€ linear_regression/
â”‚   â”‚   â”œâ”€â”€ linear_regression.py
â”‚   â”‚   â”œâ”€â”€ linear_regression.ipynb
â”‚   â”‚   â””â”€â”€ paper.pdf
â”‚   â””â”€â”€ logistic_regression/
â”‚       â”œâ”€â”€ logistic_regression.py
â”‚       â”œâ”€â”€ logistic_regression.ipynb
â”‚       â””â”€â”€ paper.pdf
â”œâ”€â”€ unsupervised/
â”‚   â”œâ”€â”€ kmeans/
â”‚   â”‚   â”œâ”€â”€ kmeans.py
â”‚   â”‚   â”œâ”€â”€ kmeans.ipynb
â”‚   â”‚   â””â”€â”€ paper.pdf
â”‚   â””â”€â”€ pca/
â”‚       â”œâ”€â”€ pca.py
â”‚       â”œâ”€â”€ pca.ipynb
â”‚       â””â”€â”€ paper.pdf
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

# ğŸ“– Research Papers

Every algorithm includes its foundational research paper ğŸ“„.  
Examples:  
- `supervised/linear_regression/paper.pdf` â†’ Linear Regression theory  
- `unsupervised/kmeans/paper.pdf` â†’ K-Means original paper  

This way, you can connect **code â†” theory** easily.  

---

## ğŸ’» How to Use

Clone the repo and dive in!  
```bash
git clone https://github.com/Ananddd06/Machine_Learning_indepth_notes.git
cd Machine_Learning_indepth_notes
```

To run any program
```bash
cd supervised/linear_regression
python linear_regression.py
```
ğŸ‘‰ Make sure you install dependencies first:

```bash
pip install -r requirements.txt

```

## ğŸ¤ Contribute

We ğŸ’™ contributions! You can:
- â• Add new algorithms  
- ğŸ““ Improve Jupyter notebooks with visualizations  
- ğŸ“„ Upload missing research papers  
- ğŸ›  Refactor / optimize existing code  
- âœ¨ Suggest new features  

### Steps to contribute:
1. ğŸ´ Fork this repo  
2. ğŸŒ¿ Create a branch (e.g., `add/naive_bayes`)  
3. ğŸ’¾ Commit changes  
4. ğŸ“¬ Open a Pull Request  

### ğŸš€ Future Roadmap
- Supervised Learning algorithms
- Unsupervised Learning algorithms
- NLP implementations (from scratch) ğŸ“
- Deep Learning basics ğŸ§ 
- Transformers âš¡

#### â­ Star My Repo

Hey there! ğŸ™Œ

If you find this project helpful, please **star â­ the repository** and keep learning ğŸ“šâœ¨.

With love â¤ï¸,
**Anand**

