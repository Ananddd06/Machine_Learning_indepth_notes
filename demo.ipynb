{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46989625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Eigenvalues: [2. 3.]\n",
      "üß≠ Eigenvectors:\n",
      " [[1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Symmetric matrix (like covariance)\n",
    "import numpy as np \n",
    "A = np.array([[2, 0],\n",
    "              [0, 3]])\n",
    "\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(A)\n",
    "print(\"üîç Eigenvalues:\", eigen_vals)\n",
    "print(\"üß≠ Eigenvectors:\\n\", eigen_vecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fe28ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature count: 30\n",
      "Matrix rank: 30\n",
      "Baseline Accuracy: 0.5\n",
      "PCA Accuracy: 0.5\n",
      "Feature Selection Accuracy: 0.5\n",
      "Ridge Classifier Accuracy: 0.5\n",
      "\n",
      "‚úÖ Final Model Comparison:\n",
      "                  Model  Accuracy\n",
      "0           Baseline LR       0.5\n",
      "1              PCA + LR       0.5\n",
      "2  Variance Select + LR       0.5\n",
      "3      Ridge Classifier       0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy.linalg import matrix_rank\n",
    "\n",
    "# 1Ô∏è‚É£ Simulate Data with Redundant Features\n",
    "np.random.seed(42)\n",
    "X_orig = np.random.randn(200, 20)\n",
    "X_redundant = X_orig[:, :10] + 0.01 * np.random.randn(200, 10)  # Add linear dependencies\n",
    "X = np.hstack([X_orig, X_redundant])\n",
    "y = np.random.randint(0, 2, 200)\n",
    "\n",
    "print(\"Feature count:\", X.shape[1])\n",
    "print(\"Matrix rank:\", matrix_rank(X))  # Check rank before anything\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# 2Ô∏è‚É£ Baseline: Logistic Regression (no fix)\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_std, y_train)\n",
    "y_pred = lr.predict(X_test_std)\n",
    "baseline_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Baseline Accuracy:\", baseline_acc)\n",
    "\n",
    "# 3Ô∏è‚É£ PCA: Dimensionality Reduction\n",
    "pca = PCA(n_components=matrix_rank(X))  # Use rank as optimal number of components\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "lr_pca = LogisticRegression(max_iter=1000)\n",
    "lr_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = lr_pca.predict(X_test_pca)\n",
    "pca_acc = accuracy_score(y_test, y_pred_pca)\n",
    "print(\"PCA Accuracy:\", pca_acc)\n",
    "\n",
    "# 4Ô∏è‚É£ Variance Threshold (Feature Selection)\n",
    "sel = VarianceThreshold(threshold=0.01)\n",
    "X_train_sel = sel.fit_transform(X_train_std)\n",
    "X_test_sel = sel.transform(X_test_std)\n",
    "\n",
    "lr_sel = LogisticRegression(max_iter=1000)\n",
    "lr_sel.fit(X_train_sel, y_train)\n",
    "y_pred_sel = lr_sel.predict(X_test_sel)\n",
    "sel_acc = accuracy_score(y_test, y_pred_sel)\n",
    "print(\"Feature Selection Accuracy:\", sel_acc)\n",
    "\n",
    "# 5Ô∏è‚É£ Ridge Classifier (Regularized Linear Model)\n",
    "ridge = RidgeClassifier(alpha=1.0)\n",
    "ridge.fit(X_train_std, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test_std)\n",
    "ridge_acc = accuracy_score(y_test, y_pred_ridge)\n",
    "print(\"Ridge Classifier Accuracy:\", ridge_acc)\n",
    "\n",
    "# 6Ô∏è‚É£ Final Report\n",
    "print(\"\\n‚úÖ Final Model Comparison:\")\n",
    "df = pd.DataFrame({\n",
    "    'Model': ['Baseline LR', 'PCA + LR', 'Variance Select + LR', 'Ridge Classifier'],\n",
    "    'Accuracy': [baseline_acc, pca_acc, sel_acc, ridge_acc]\n",
    "})\n",
    "print(df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1305dd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature count: 30\n",
      "üìâ Matrix rank: 30 (out of 30)\n",
      "\n",
      "‚úÖ Final Model Comparison:\n",
      "              Model  Accuracy\n",
      "0  Ridge Classifier     0.950\n",
      "1       Baseline LR     0.875\n",
      "2          PCA + LR     0.875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy.linalg import matrix_rank\n",
    "\n",
    "# 1Ô∏è‚É£ Simulate Redundant Data with Learnable Signal\n",
    "np.random.seed(42)\n",
    "n_samples, n_features = 200, 30\n",
    "\n",
    "# 20 original features\n",
    "X_orig = np.random.randn(n_samples, 20)\n",
    "\n",
    "# 10 redundant features = linear combos\n",
    "X_redundant = X_orig[:, :10] + 0.001 * np.random.randn(n_samples, 10)\n",
    "\n",
    "# Combine\n",
    "X = np.hstack([X_orig, X_redundant])\n",
    "true_rank = matrix_rank(X)\n",
    "print(f\"Feature count: {X.shape[1]}\")\n",
    "print(f\"üìâ Matrix rank: {true_rank} (out of {X.shape[1]})\")\n",
    "\n",
    "# Create target using linear signal\n",
    "true_weights = np.random.randn(X.shape[1])\n",
    "y_score = X @ true_weights + 0.5 * np.random.randn(n_samples)\n",
    "y = (y_score > np.median(y_score)).astype(int)\n",
    "\n",
    "# 2Ô∏è‚É£ Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3Ô∏è‚É£ Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# 4Ô∏è‚É£ Baseline Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_std, y_train)\n",
    "baseline_acc = accuracy_score(y_test, lr.predict(X_test_std))\n",
    "\n",
    "# 5Ô∏è‚É£ PCA Based on Rank\n",
    "pca = PCA(n_components=true_rank)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "lr_pca = LogisticRegression(max_iter=1000)\n",
    "lr_pca.fit(X_train_pca, y_train)\n",
    "pca_acc = accuracy_score(y_test, lr_pca.predict(X_test_pca))\n",
    "\n",
    "# 6Ô∏è‚É£ Ridge Regularization\n",
    "ridge = RidgeClassifier(alpha=1.0)\n",
    "ridge.fit(X_train_std, y_train)\n",
    "ridge_acc = accuracy_score(y_test, ridge.predict(X_test_std))\n",
    "\n",
    "# 7Ô∏è‚É£ Final Report\n",
    "df = pd.DataFrame({\n",
    "    'Model': ['Baseline LR', 'PCA + LR', 'Ridge Classifier'],\n",
    "    'Accuracy': [baseline_acc, pca_acc, ridge_acc]\n",
    "})\n",
    "print(\"\\n‚úÖ Final Model Comparison:\")\n",
    "print(df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
